{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "import mysql.connector\n",
    "from functools import partial\n",
    "import json\n",
    "\n",
    "database = mysql.connector.connect(\n",
    "    user='root', \n",
    "    password='password',\n",
    "    host='127.0.0.1', \n",
    "    port=3307,\n",
    "    database=\"TPCH\",\n",
    ")\n",
    "\n",
    "cursor = database.cursor()\n",
    "\n",
    "def partial_transformer(node, table_index_info):\n",
    "    if isinstance(node, sqlglot.exp.Table):\n",
    "        table_name = node.this.output_name\n",
    "        if table_name in table_index_info:\n",
    "            use_index_flag = table_index_info[table_name][\"use_index_flag\"]\n",
    "            indexes = [ f\"index_{table_name}_{column}\" for column in table_index_info[table_name][\"indexes\"]]\n",
    "        else:\n",
    "            use_index_flag = True\n",
    "            indexes = list()\n",
    "\n",
    "        table_hint = sqlglot.exp.IndexTableHint()\n",
    "        table_hint.set(\"this\", \"FORCE\" if use_index_flag else \"IGNORE\")\n",
    "        indexes_identifier = sqlglot.exp.Identifier()\n",
    "        indexes_identifier.set(\"this\", \", \".join(indexes))\n",
    "        table_hint.set(\"expressions\", table_hint.expressions + [indexes_identifier])\n",
    "        node.set(\"hints\", node.expressions + [table_hint])\n",
    "        return node\n",
    "    return node\n",
    "\n",
    "def get_query_cost(query, table_index_info) -> float:\n",
    "    expression_tree = sqlglot.parse_one(query)\n",
    "    transformer = partial(partial_transformer, table_index_info=table_index_info)\n",
    "    transformed_tree = expression_tree.transform(transformer)\n",
    "    index_specified_query = transformed_tree.sql()\n",
    "    print(index_specified_query)\n",
    "    cursor.execute(f\"EXPLAIN FORMAT='JSON' {index_specified_query}\")\n",
    "    \n",
    "\n",
    "    query_cost = json.loads(cursor.fetchall()[0][0])[\"query_block\"][\"cost_info\"][\"query_cost\"]\n",
    "\n",
    "    return float(query_cost)\n",
    "\n",
    "def get_index_cost(table_index_info) -> float:\n",
    "    index_name_list = []\n",
    "    for table_name in table_index_info:\n",
    "        for column in table_index_info[table_name][\"indexes\"]:\n",
    "            index_name_list.append(f\"index_{table_name}_{column}\")\n",
    "\n",
    "    index_name_list_string = \"('\"+ \"','\".join(index_name_list) + \"')\"\n",
    "        \n",
    "    cursor.execute(f\"SELECT ROUND(SUM(stat_value * @@innodb_page_size / 1024 / 1024), 2) size_in_mb FROM mysql.innodb_index_stats WHERE stat_name = 'size' AND index_name != 'PRIMARY' AND database_name = 'TPCH' AND index_name IN {index_name_list_string}\")\n",
    "    return float(cursor.fetchone()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "1235 (42000): This version of MySQL doesn't yet support 'EXPLAIN ANALYZE with JSON format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/CS598/myenv/lib/python3.8/site-packages/mysql/connector/connection_cext.py:443\u001b[0m, in \u001b[0;36mCMySQLConnection.get_rows\u001b[0;34m(self, count, binary, columns, raw, prep_stmt)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cmysql\u001b[39m.\u001b[39mraw(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 443\u001b[0m row \u001b[39m=\u001b[39m fetch_row()\n\u001b[1;32m    444\u001b[0m \u001b[39mwhile\u001b[39;00m row:\n",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m: This version of MySQL doesn't yet support 'EXPLAIN ANALYZE with JSON format'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/mgartenhaus/CS598/cost_functions.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mgartenhaus/CS598/cost_functions.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cursor\u001b[39m.\u001b[39mexecute(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEXPLAIN ANALYZE FORMAT=JSON \u001b[39m\u001b[39m{\u001b[39;00mqueries[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mgartenhaus/CS598/cost_functions.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cursor\u001b[39m.\u001b[39;49mfetchone()\n",
      "File \u001b[0;32m~/CS598/myenv/lib/python3.8/site-packages/mysql/connector/cursor_cext.py:674\u001b[0m, in \u001b[0;36mCMySQLCursor.fetchone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nextrow\n\u001b[1;32m    673\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m row \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cnx\u001b[39m.\u001b[39munread_result:\n\u001b[0;32m--> 674\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cnx\u001b[39m.\u001b[39;49mget_row()\n\u001b[1;32m    676\u001b[0m \u001b[39mif\u001b[39;00m row \u001b[39mand\u001b[39;00m row[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    677\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nextrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cnx\u001b[39m.\u001b[39mget_row()\n",
      "File \u001b[0;32m~/CS598/myenv/lib/python3.8/site-packages/mysql/connector/connection_cext.py:487\u001b[0m, in \u001b[0;36mCMySQLConnection.get_row\u001b[0;34m(self, binary, columns, raw, prep_stmt)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get the next rows returned by the MySQL server\"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     rows, eof \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_rows(\n\u001b[1;32m    488\u001b[0m         count\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    489\u001b[0m         binary\u001b[39m=\u001b[39;49mbinary,\n\u001b[1;32m    490\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m    491\u001b[0m         raw\u001b[39m=\u001b[39;49mraw,\n\u001b[1;32m    492\u001b[0m         prep_stmt\u001b[39m=\u001b[39;49mprep_stmt,\n\u001b[1;32m    493\u001b[0m     )\n\u001b[1;32m    494\u001b[0m     \u001b[39mif\u001b[39;00m rows:\n\u001b[1;32m    495\u001b[0m         \u001b[39mreturn\u001b[39;00m (rows[\u001b[39m0\u001b[39m], eof)\n",
      "File \u001b[0;32m~/CS598/myenv/lib/python3.8/site-packages/mysql/connector/connection_cext.py:472\u001b[0m, in \u001b[0;36mCMySQLConnection.get_rows\u001b[0;34m(self, count, binary, columns, raw, prep_stmt)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[39mraise\u001b[39;00m InterfaceError(\u001b[39mstr\u001b[39m(err)) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_result()\n\u001b[0;32m--> 472\u001b[0m     \u001b[39mraise\u001b[39;00m get_mysql_exception(\n\u001b[1;32m    473\u001b[0m         msg\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39mmsg, errno\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39merrno, sqlstate\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39msqlstate\n\u001b[1;32m    474\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[39mreturn\u001b[39;00m rows, _eof\n",
      "\u001b[0;31mProgrammingError\u001b[0m: 1235 (42000): This version of MySQL doesn't yet support 'EXPLAIN ANALYZE with JSON format'"
     ]
    }
   ],
   "source": [
    "cursor.execute(f\"EXPLAIN ANALYZE FORMAT=JSON {queries[1]}\")\n",
    "cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/mgartenhaus/CS598/cost_functions.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mgartenhaus/CS598/cost_functions.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cursor\u001b[39m.\u001b[39mexecute(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEXPLAIN ANALYZE \u001b[39m\u001b[39m{\u001b[39;00mqueries[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mgartenhaus/CS598/cost_functions.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(json\u001b[39m.\u001b[39;49mloads(cursor\u001b[39m.\u001b[39;49mfetchall()[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]))\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.8/3.8.18/Frameworks/Python.framework/Versions/3.8/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[39mdel\u001b[39;00m kw[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.8/3.8.18/Frameworks/Python.framework/Versions/3.8/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.8/3.8.18/Frameworks/Python.framework/Versions/3.8/lib/python3.8/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "cursor.execute(f\"EXPLAIN ANALYZE {queries[1]}\")\n",
    "print(json.loads(cursor.fetchall()[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/zns3zzl52ngb09pgfbbnb3pm0000gn/T/ipykernel_89698/1569032752.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  tables_list = pd.read_sql(\"SHOW TABLES\", database)[\"Tables_in_TPCH\"].tolist()\n",
      "/var/folders/k2/zns3zzl52ngb09pgfbbnb3pm0000gn/T/ipykernel_89698/1569032752.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  query_result = pd.read_sql(f\"SHOW indexes FROM {table} WHERE key_name LIKE 'index_%'\", database)\n",
      "/var/folders/k2/zns3zzl52ngb09pgfbbnb3pm0000gn/T/ipykernel_89698/1569032752.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  query_result = pd.read_sql(f\"SHOW indexes FROM {table} WHERE key_name LIKE 'index_%'\", database)\n",
      "/var/folders/k2/zns3zzl52ngb09pgfbbnb3pm0000gn/T/ipykernel_89698/1569032752.py:5: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  query_result = pd.read_sql(f\"SHOW indexes FROM {table} WHERE key_name LIKE 'index_%'\", database)\n"
     ]
    }
   ],
   "source": [
    "tables_list = pd.read_sql(\"SHOW TABLES\", database)[\"Tables_in_TPCH\"].tolist()\n",
    "index_table_mapping = dict()\n",
    "index_list = list()\n",
    "for table in tables_list:\n",
    "    query_result = pd.read_sql(f\"SHOW indexes FROM {table} WHERE key_name LIKE 'index_%'\", database)\n",
    "    index_table_mapping[table] = query_result[\"Column_name\"].tolist()\n",
    "    index_list += query_result[\"Key_name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index_customer_c_nationkey',\n",
       " 'index_customer_c_mktsegment',\n",
       " 'index_lineitem_l_partkey',\n",
       " 'index_lineitem_l_suppkey',\n",
       " 'index_lineitem_l_linenumber',\n",
       " 'index_lineitem_l_quantity',\n",
       " 'index_lineitem_l_discount',\n",
       " 'index_lineitem_l_tax',\n",
       " 'index_lineitem_l_returnflag',\n",
       " 'index_lineitem_l_linestatus',\n",
       " 'index_lineitem_l_shipdate',\n",
       " 'index_lineitem_l_commitdate',\n",
       " 'index_lineitem_l_receiptdate',\n",
       " 'index_lineitem_l_shipinstruct',\n",
       " 'index_lineitem_l_shipmode',\n",
       " 'index_orders_o_custkey',\n",
       " 'index_orders_o_orderstatus',\n",
       " 'index_orders_o_orderpriority',\n",
       " 'index_orders_o_clerk',\n",
       " 'index_orders_o_shippriority',\n",
       " 'index_part_p_mfgr',\n",
       " 'index_part_p_brand',\n",
       " 'index_part_p_type',\n",
       " 'index_part_p_size',\n",
       " 'index_part_p_container',\n",
       " 'index_partsupp_ps_suppkey']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = index_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = [x.split(\"_\")[1] for x in indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_index_info = dict()\n",
    "for i in range(len(indexes)):\n",
    "    index = indexes[i]\n",
    "    table = table_names[i]\n",
    "    index_col = index.replace(f\"index_{table}_\", \"\")\n",
    "    if table in table_index_info:\n",
    "        table_index_info[table][\"indexes\"].append(index_col)\n",
    "    else:\n",
    "        table_index_info[table] = {\n",
    "            \"use_index_flag\": True,\n",
    "            \"indexes\": [index_col],\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'customer': {'use_index_flag': True,\n",
       "  'indexes': ['c_nationkey', 'c_mktsegment']},\n",
       " 'lineitem': {'use_index_flag': True,\n",
       "  'indexes': ['l_partkey', 'l_suppkey', 'l_linenumber']}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_index_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_reader = open(\"queries/test_queries.sql\")\n",
    "queries = sql_reader.read().split(\";\")\n",
    "sql_reader.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find columns involved in join and columns involved in where clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_expression = sqlglot.parse_one(queries[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheres = list(test_expression.find_all(sqlglot.exp.Where))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = wheres[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(sqlglot.exp.Where, sqlglot.exp.Subquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_walk_prune(node, parent, arg_key):\n",
    "    exclude = isinstance(node, sqlglot.exp.Subquery)\n",
    "    return exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((IDENTIFIER this: ps_supplycost, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: ps_supplycost, quoted: False)), 'this')\n",
      "((IDENTIFIER this: ps_supplycost, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: ps_supplycost, quoted: False)), 'this')\n",
      "((IDENTIFIER this: ps_supplycost, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: ps_supplycost, quoted: False)), 'this')\n",
      "((IDENTIFIER this: r_name, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: r_name, quoted: False)), 'this')\n",
      "((IDENTIFIER this: r_name, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: r_name, quoted: False)), 'this')\n",
      "((IDENTIFIER this: r_name, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: r_name, quoted: False)), 'this')\n",
      "((IDENTIFIER this: n_regionkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: n_regionkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: n_regionkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: n_regionkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: n_regionkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: n_regionkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: r_regionkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: r_regionkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: r_regionkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: r_regionkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: r_regionkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: r_regionkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: s_nationkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: s_nationkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: s_nationkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: s_nationkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: s_nationkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: s_nationkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: n_nationkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: n_nationkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: n_nationkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: n_nationkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: n_nationkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: n_nationkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: p_type, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: p_type, quoted: False)), 'this')\n",
      "((IDENTIFIER this: p_type, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: p_type, quoted: False)), 'this')\n",
      "((IDENTIFIER this: p_type, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: p_type, quoted: False)), 'this')\n",
      "((IDENTIFIER this: p_size, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: p_size, quoted: False)), 'this')\n",
      "((IDENTIFIER this: p_size, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: p_size, quoted: False)), 'this')\n",
      "((IDENTIFIER this: p_size, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: p_size, quoted: False)), 'this')\n",
      "((IDENTIFIER this: p_partkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: p_partkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: p_partkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: p_partkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: p_partkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: p_partkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: ps_partkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: ps_partkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: ps_partkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: ps_partkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: ps_partkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: ps_partkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: s_suppkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: s_suppkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: s_suppkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: s_suppkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: s_suppkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: s_suppkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: ps_suppkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: ps_suppkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: ps_suppkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: ps_suppkey, quoted: False)), 'this')\n",
      "((IDENTIFIER this: ps_suppkey, quoted: False), (COLUMN this: \n",
      "  (IDENTIFIER this: ps_suppkey, quoted: False)), 'this')\n"
     ]
    }
   ],
   "source": [
    "for x in testing.walk(prune=my_walk_prune):\n",
    "    for y in x:\n",
    "        if isinstance(x[0], sqlglot.exp.Identifier):\n",
    "            print(x)\n",
    "    # print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(WHERE this: \n",
       "   (AND this: \n",
       "     (AND this: \n",
       "       (AND this: \n",
       "         (AND this: \n",
       "           (AND this: \n",
       "             (AND this: \n",
       "               (AND this: \n",
       "                 (EQ this: \n",
       "                   (COLUMN this: \n",
       "                     (IDENTIFIER this: p_partkey, quoted: False)), expression: \n",
       "                   (COLUMN this: \n",
       "                     (IDENTIFIER this: ps_partkey, quoted: False))), expression: \n",
       "                 (EQ this: \n",
       "                   (COLUMN this: \n",
       "                     (IDENTIFIER this: s_suppkey, quoted: False)), expression: \n",
       "                   (COLUMN this: \n",
       "                     (IDENTIFIER this: ps_suppkey, quoted: False)))), expression: \n",
       "               (EQ this: \n",
       "                 (COLUMN this: \n",
       "                   (IDENTIFIER this: p_size, quoted: False)), expression: \n",
       "                 (LITERAL this: 32, is_string: False))), expression: \n",
       "             (LIKE this: \n",
       "               (COLUMN this: \n",
       "                 (IDENTIFIER this: p_type, quoted: False)), expression: \n",
       "               (LITERAL this: %COPPER, is_string: True))), expression: \n",
       "           (EQ this: \n",
       "             (COLUMN this: \n",
       "               (IDENTIFIER this: s_nationkey, quoted: False)), expression: \n",
       "             (COLUMN this: \n",
       "               (IDENTIFIER this: n_nationkey, quoted: False)))), expression: \n",
       "         (EQ this: \n",
       "           (COLUMN this: \n",
       "             (IDENTIFIER this: n_regionkey, quoted: False)), expression: \n",
       "           (COLUMN this: \n",
       "             (IDENTIFIER this: r_regionkey, quoted: False)))), expression: \n",
       "       (EQ this: \n",
       "         (COLUMN this: \n",
       "           (IDENTIFIER this: r_name, quoted: False)), expression: \n",
       "         (LITERAL this: AMERICA, is_string: True))), expression: \n",
       "     (EQ this: \n",
       "       (COLUMN this: \n",
       "         (IDENTIFIER this: ps_supplycost, quoted: False)), expression: \n",
       "       (SUBQUERY this: \n",
       "         (SELECT expressions: \n",
       "           (MIN this: \n",
       "             (COLUMN this: \n",
       "               (IDENTIFIER this: ps_supplycost, quoted: False))), from: \n",
       "           (FROM this: \n",
       "             (TABLE this: \n",
       "               (IDENTIFIER this: partsupp, quoted: False))), joins: \n",
       "           (JOIN this: \n",
       "             (TABLE this: \n",
       "               (IDENTIFIER this: supplier, quoted: False))), \n",
       "           (JOIN this: \n",
       "             (TABLE this: \n",
       "               (IDENTIFIER this: nation, quoted: False))), \n",
       "           (JOIN this: \n",
       "             (TABLE this: \n",
       "               (IDENTIFIER this: region, quoted: False))), where: \n",
       "           (WHERE this: \n",
       "             (AND this: \n",
       "               (AND this: \n",
       "                 (AND this: \n",
       "                   (AND this: \n",
       "                     (EQ this: \n",
       "                       (COLUMN this: \n",
       "                         (IDENTIFIER this: p_partkey, quoted: False)), expression: \n",
       "                       (COLUMN this: \n",
       "                         (IDENTIFIER this: ps_partkey, quoted: False))), expression: \n",
       "                     (EQ this: \n",
       "                       (COLUMN this: \n",
       "                         (IDENTIFIER this: s_suppkey, quoted: False)), expression: \n",
       "                       (COLUMN this: \n",
       "                         (IDENTIFIER this: ps_suppkey, quoted: False)))), expression: \n",
       "                   (EQ this: \n",
       "                     (COLUMN this: \n",
       "                       (IDENTIFIER this: s_nationkey, quoted: False)), expression: \n",
       "                     (COLUMN this: \n",
       "                       (IDENTIFIER this: n_nationkey, quoted: False)))), expression: \n",
       "                 (EQ this: \n",
       "                   (COLUMN this: \n",
       "                     (IDENTIFIER this: n_regionkey, quoted: False)), expression: \n",
       "                   (COLUMN this: \n",
       "                     (IDENTIFIER this: r_regionkey, quoted: False)))), expression: \n",
       "               (EQ this: \n",
       "                 (COLUMN this: \n",
       "                   (IDENTIFIER this: r_name, quoted: False)), expression: \n",
       "                 (LITERAL this: AMERICA, is_string: True))))))))),\n",
       " (WHERE this: \n",
       "   (AND this: \n",
       "     (AND this: \n",
       "       (AND this: \n",
       "         (AND this: \n",
       "           (EQ this: \n",
       "             (COLUMN this: \n",
       "               (IDENTIFIER this: p_partkey, quoted: False)), expression: \n",
       "             (COLUMN this: \n",
       "               (IDENTIFIER this: ps_partkey, quoted: False))), expression: \n",
       "           (EQ this: \n",
       "             (COLUMN this: \n",
       "               (IDENTIFIER this: s_suppkey, quoted: False)), expression: \n",
       "             (COLUMN this: \n",
       "               (IDENTIFIER this: ps_suppkey, quoted: False)))), expression: \n",
       "         (EQ this: \n",
       "           (COLUMN this: \n",
       "             (IDENTIFIER this: s_nationkey, quoted: False)), expression: \n",
       "           (COLUMN this: \n",
       "             (IDENTIFIER this: n_nationkey, quoted: False)))), expression: \n",
       "       (EQ this: \n",
       "         (COLUMN this: \n",
       "           (IDENTIFIER this: n_regionkey, quoted: False)), expression: \n",
       "         (COLUMN this: \n",
       "           (IDENTIFIER this: r_regionkey, quoted: False)))), expression: \n",
       "     (EQ this: \n",
       "       (COLUMN this: \n",
       "         (IDENTIFIER this: r_name, quoted: False)), expression: \n",
       "       (LITERAL this: AMERICA, is_string: True))))]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(wheres[0].find_all(sqlglot.exp.Where))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(IDENTIFIER this: ps_supplycost, quoted: False),\n",
       "  (IDENTIFIER this: r_name, quoted: False),\n",
       "  (IDENTIFIER this: n_regionkey, quoted: False),\n",
       "  (IDENTIFIER this: r_regionkey, quoted: False),\n",
       "  (IDENTIFIER this: s_nationkey, quoted: False),\n",
       "  (IDENTIFIER this: n_nationkey, quoted: False),\n",
       "  (IDENTIFIER this: ps_supplycost, quoted: False),\n",
       "  (IDENTIFIER this: partsupp, quoted: False),\n",
       "  (IDENTIFIER this: supplier, quoted: False),\n",
       "  (IDENTIFIER this: nation, quoted: False),\n",
       "  (IDENTIFIER this: region, quoted: False),\n",
       "  (IDENTIFIER this: p_type, quoted: False),\n",
       "  (IDENTIFIER this: p_size, quoted: False),\n",
       "  (IDENTIFIER this: r_name, quoted: False),\n",
       "  (IDENTIFIER this: p_partkey, quoted: False),\n",
       "  (IDENTIFIER this: ps_partkey, quoted: False),\n",
       "  (IDENTIFIER this: s_suppkey, quoted: False),\n",
       "  (IDENTIFIER this: ps_suppkey, quoted: False),\n",
       "  (IDENTIFIER this: n_regionkey, quoted: False),\n",
       "  (IDENTIFIER this: r_regionkey, quoted: False),\n",
       "  (IDENTIFIER this: s_nationkey, quoted: False),\n",
       "  (IDENTIFIER this: n_nationkey, quoted: False),\n",
       "  (IDENTIFIER this: p_partkey, quoted: False),\n",
       "  (IDENTIFIER this: ps_partkey, quoted: False),\n",
       "  (IDENTIFIER this: s_suppkey, quoted: False),\n",
       "  (IDENTIFIER this: ps_suppkey, quoted: False)],\n",
       " [(IDENTIFIER this: r_name, quoted: False),\n",
       "  (IDENTIFIER this: n_regionkey, quoted: False),\n",
       "  (IDENTIFIER this: r_regionkey, quoted: False),\n",
       "  (IDENTIFIER this: s_nationkey, quoted: False),\n",
       "  (IDENTIFIER this: n_nationkey, quoted: False),\n",
       "  (IDENTIFIER this: p_partkey, quoted: False),\n",
       "  (IDENTIFIER this: ps_partkey, quoted: False),\n",
       "  (IDENTIFIER this: s_suppkey, quoted: False),\n",
       "  (IDENTIFIER this: ps_suppkey, quoted: False)]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(x.find_all(sqlglot.exp.Identifier)) for x in ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* using 1697822052 as a seed to the RNG */ SELECT l_returnflag, l_linestatus, SUM(l_quantity) AS sum_qty, SUM(l_extendedprice) AS sum_base_price, SUM(l_extendedprice * (1 - l_discount)) AS sum_disc_price, SUM(l_extendedprice * (1 - l_discount) * (1 + l_tax)) AS sum_charge, AVG(l_quantity) AS avg_qty, AVG(l_extendedprice) AS avg_price, AVG(l_discount) AS avg_disc, COUNT(*) AS count_order FROM lineitem FORCE INDEX () WHERE l_shipdate <= CAST('1998-12-01' AS DATE) - INTERVAL '83' day GROUP BY l_returnflag, l_linestatus ORDER BY l_returnflag, l_linestatus\n"
     ]
    },
    {
     "ename": "ProgrammingError",
     "evalue": "1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ') WHERE l_shipdate <= CAST('1998-12-01' AS DATE) - INTERVAL '83' day GROUP BY l_' at line 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/CS598/myenv/lib/python3.8/site-packages/mysql/connector/connection_cext.py:639\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    638\u001b[0m         query \u001b[39m=\u001b[39m query\u001b[39m.\u001b[39mencode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 639\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmysql\u001b[39m.\u001b[39;49mquery(\n\u001b[1;32m    640\u001b[0m         query,\n\u001b[1;32m    641\u001b[0m         raw\u001b[39m=\u001b[39;49mraw,\n\u001b[1;32m    642\u001b[0m         buffered\u001b[39m=\u001b[39;49mbuffered,\n\u001b[1;32m    643\u001b[0m         raw_as_string\u001b[39m=\u001b[39;49mraw_as_string,\n\u001b[1;32m    644\u001b[0m         query_attrs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery_attrs,\n\u001b[1;32m    645\u001b[0m     )\n\u001b[1;32m    646\u001b[0m \u001b[39mexcept\u001b[39;00m MySQLInterfaceError \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mMySQLInterfaceError\u001b[0m: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ') WHERE l_shipdate <= CAST('1998-12-01' AS DATE) - INTERVAL '83' day GROUP BY l_' at line 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/mgartenhaus/CS598/cost_functions.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mgartenhaus/CS598/cost_functions.ipynb#Y101sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m base_cost \u001b[39m=\u001b[39m get_query_cost(queries[\u001b[39m0\u001b[39;49m], \u001b[39mdict\u001b[39;49m())\n",
      "\u001b[1;32m/Users/mgartenhaus/CS598/cost_functions.ipynb Cell 4\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mgartenhaus/CS598/cost_functions.ipynb#Y101sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m index_specified_query \u001b[39m=\u001b[39m transformed_tree\u001b[39m.\u001b[39msql()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mgartenhaus/CS598/cost_functions.ipynb#Y101sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mprint\u001b[39m(index_specified_query)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mgartenhaus/CS598/cost_functions.ipynb#Y101sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m cursor\u001b[39m.\u001b[39;49mexecute(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEXPLAIN FORMAT=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mJSON\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m{\u001b[39;49;00mindex_specified_query\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mgartenhaus/CS598/cost_functions.ipynb#Y101sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m query_cost \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(cursor\u001b[39m.\u001b[39mfetchall()[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])[\u001b[39m\"\u001b[39m\u001b[39mquery_block\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcost_info\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mquery_cost\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mgartenhaus/CS598/cost_functions.ipynb#Y101sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39m(query_cost)\n",
      "File \u001b[0;32m~/CS598/myenv/lib/python3.8/site-packages/mysql/connector/cursor_cext.py:330\u001b[0m, in \u001b[0;36mCMySQLCursor.execute\u001b[0;34m(self, operation, params, multi)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[39mraise\u001b[39;00m ProgrammingError(\n\u001b[1;32m    326\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mNot all parameters were used in the SQL statement\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    327\u001b[0m             )\n\u001b[1;32m    329\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cnx\u001b[39m.\u001b[39;49mcmd_query(\n\u001b[1;32m    331\u001b[0m         stmt,\n\u001b[1;32m    332\u001b[0m         raw\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw,\n\u001b[1;32m    333\u001b[0m         buffered\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffered,\n\u001b[1;32m    334\u001b[0m         raw_as_string\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_as_string,\n\u001b[1;32m    335\u001b[0m     )\n\u001b[1;32m    336\u001b[0m \u001b[39mexcept\u001b[39;00m MySQLInterfaceError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    337\u001b[0m     \u001b[39mraise\u001b[39;00m get_mysql_exception(\n\u001b[1;32m    338\u001b[0m         msg\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39mmsg, errno\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39merrno, sqlstate\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39msqlstate\n\u001b[1;32m    339\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "File \u001b[0;32m~/CS598/myenv/lib/python3.8/site-packages/mysql/connector/opentelemetry/context_propagation.py:77\u001b[0m, in \u001b[0;36mwith_context_propagation.<locals>.wrapper\u001b[0;34m(cnx, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Context propagation decorator.\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m OTEL_ENABLED \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m cnx\u001b[39m.\u001b[39motel_context_propagation:\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mreturn\u001b[39;00m method(cnx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     79\u001b[0m current_span \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mget_current_span()\n\u001b[1;32m     80\u001b[0m tp_header \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/CS598/myenv/lib/python3.8/site-packages/mysql/connector/connection_cext.py:647\u001b[0m, in \u001b[0;36mCMySQLConnection.cmd_query\u001b[0;34m(self, query, raw, buffered, raw_as_string)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cmysql\u001b[39m.\u001b[39mquery(\n\u001b[1;32m    640\u001b[0m         query,\n\u001b[1;32m    641\u001b[0m         raw\u001b[39m=\u001b[39mraw,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    644\u001b[0m         query_attrs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_attrs,\n\u001b[1;32m    645\u001b[0m     )\n\u001b[1;32m    646\u001b[0m \u001b[39mexcept\u001b[39;00m MySQLInterfaceError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 647\u001b[0m     \u001b[39mraise\u001b[39;00m get_mysql_exception(\n\u001b[1;32m    648\u001b[0m         err\u001b[39m.\u001b[39merrno, msg\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39mmsg, sqlstate\u001b[39m=\u001b[39merr\u001b[39m.\u001b[39msqlstate\n\u001b[1;32m    649\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    650\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    651\u001b[0m     addr \u001b[39m=\u001b[39m (\n\u001b[1;32m    652\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unix_socket \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unix_socket \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_host\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_port\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    653\u001b[0m     )\n",
      "\u001b[0;31mProgrammingError\u001b[0m: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ') WHERE l_shipdate <= CAST('1998-12-01' AS DATE) - INTERVAL '83' day GROUP BY l_' at line 1"
     ]
    }
   ],
   "source": [
    "base_cost = get_query_cost(queries[0], dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- using 1697822052 as a seed to the RNG\n",
      "\n",
      "\n",
      "\n",
      "select\n",
      "\tl_returnflag,\n",
      "\tl_linestatus,\n",
      "\tsum(l_quantity) as sum_qty,\n",
      "\tsum(l_extendedprice) as sum_base_price,\n",
      "\tsum(l_extendedprice * (1 - l_discount)) as sum_disc_price,\n",
      "\tsum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,\n",
      "\tavg(l_quantity) as avg_qty,\n",
      "\tavg(l_extendedprice) as avg_price,\n",
      "\tavg(l_discount) as avg_disc,\n",
      "\tcount(*) as count_order\n",
      "from\n",
      "\tlineitem\n",
      "where\n",
      "\tl_shipdate <= date '1998-12-01' - interval '83' day\n",
      "group by\n",
      "\tl_returnflag,\n",
      "\tl_linestatus\n",
      "order by\n",
      "\tl_returnflag,\n",
      "\tl_linestatus\n"
     ]
    }
   ],
   "source": [
    "print(queries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space_mapping = {\n",
    "    0: \"do_nothing\",\n",
    "}\n",
    "\n",
    "max_key = 0\n",
    "for index in index_list:\n",
    "    max_key += 1\n",
    "    action_space_mapping[max_key] = f\"add_{index}\"\n",
    "\n",
    "for index in index_list:\n",
    "    max_key += 1\n",
    "    action_space_mapping[max_key] = f\"remove_{index}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'do_nothing',\n",
       " 1: 'add_index_customer_c_nationkey',\n",
       " 2: 'add_index_customer_c_mktsegment',\n",
       " 3: 'add_index_lineitem_l_partkey',\n",
       " 4: 'add_index_lineitem_l_suppkey',\n",
       " 5: 'add_index_lineitem_l_linenumber',\n",
       " 6: 'add_index_lineitem_l_quantity',\n",
       " 7: 'add_index_lineitem_l_discount',\n",
       " 8: 'add_index_lineitem_l_tax',\n",
       " 9: 'add_index_lineitem_l_returnflag',\n",
       " 10: 'add_index_lineitem_l_linestatus',\n",
       " 11: 'add_index_lineitem_l_shipdate',\n",
       " 12: 'add_index_lineitem_l_commitdate',\n",
       " 13: 'add_index_lineitem_l_receiptdate',\n",
       " 14: 'add_index_lineitem_l_shipinstruct',\n",
       " 15: 'add_index_lineitem_l_shipmode',\n",
       " 16: 'add_index_orders_o_custkey',\n",
       " 17: 'add_index_orders_o_orderstatus',\n",
       " 18: 'add_index_orders_o_orderpriority',\n",
       " 19: 'add_index_orders_o_clerk',\n",
       " 20: 'add_index_orders_o_shippriority',\n",
       " 21: 'add_index_part_p_mfgr',\n",
       " 22: 'add_index_part_p_brand',\n",
       " 23: 'add_index_part_p_type',\n",
       " 24: 'add_index_part_p_size',\n",
       " 25: 'add_index_part_p_container',\n",
       " 26: 'add_index_partsupp_ps_suppkey',\n",
       " 27: 'remove_index_customer_c_nationkey',\n",
       " 28: 'remove_index_customer_c_mktsegment',\n",
       " 29: 'remove_index_lineitem_l_partkey',\n",
       " 30: 'remove_index_lineitem_l_suppkey',\n",
       " 31: 'remove_index_lineitem_l_linenumber',\n",
       " 32: 'remove_index_lineitem_l_quantity',\n",
       " 33: 'remove_index_lineitem_l_discount',\n",
       " 34: 'remove_index_lineitem_l_tax',\n",
       " 35: 'remove_index_lineitem_l_returnflag',\n",
       " 36: 'remove_index_lineitem_l_linestatus',\n",
       " 37: 'remove_index_lineitem_l_shipdate',\n",
       " 38: 'remove_index_lineitem_l_commitdate',\n",
       " 39: 'remove_index_lineitem_l_receiptdate',\n",
       " 40: 'remove_index_lineitem_l_shipinstruct',\n",
       " 41: 'remove_index_lineitem_l_shipmode',\n",
       " 42: 'remove_index_orders_o_custkey',\n",
       " 43: 'remove_index_orders_o_orderstatus',\n",
       " 44: 'remove_index_orders_o_orderpriority',\n",
       " 45: 'remove_index_orders_o_clerk',\n",
       " 46: 'remove_index_orders_o_shippriority',\n",
       " 47: 'remove_index_part_p_mfgr',\n",
       " 48: 'remove_index_part_p_brand',\n",
       " 49: 'remove_index_part_p_type',\n",
       " 50: 'remove_index_part_p_size',\n",
       " 51: 'remove_index_part_p_container',\n",
       " 52: 'remove_index_partsupp_ps_suppkey'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-11 10:40:41.686427: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "from collections import deque\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 5\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 5\n",
    "test_episodes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_space_mapping = {   \n",
    "    x:x for x in range(100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DbEnv():\n",
    "    def __init__(self):\n",
    "        self.seed = RANDOM_SEED\n",
    "        self.observation_space = list(observation_space_mapping.keys())\n",
    "        self.action_space = list(action_space_mapping.keys())\n",
    "        self.current_indexes = []\n",
    "        self.training_complete = False\n",
    "    def reset(self):\n",
    "        if not self.training_complete:\n",
    "            self.current_indexes = []\n",
    "    def step(self, action):\n",
    "        self.current_indexes.append(action)\n",
    "        new_observation = list(observation_space_mapping.values())\n",
    "        reward = random.randint(0, 5)\n",
    "        done = False\n",
    "        info = 1\n",
    "        return new_observation, reward, done, info\n",
    "            \n",
    "    def close(self):\n",
    "        self.training_complete=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DbEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state_shape, action_shape):\n",
    "    \"\"\" The agent maps X-states to Y-actions\n",
    "    e.g. The neural network output is [.1, .7, .1, .3]\n",
    "    The highest value 0.7 is the Q-Value.\n",
    "    The index of the highest action (0.7) is action #1.\n",
    "    \"\"\"\n",
    "    learning_rate = 0.001\n",
    "    init = tf.keras.initializers.HeUniform()\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(24, input_shape=state_shape, activation='relu', kernel_initializer=init))\n",
    "    model.add(keras.layers.Dense(12, activation='relu', kernel_initializer=init))\n",
    "    model.add(keras.layers.Dense(action_shape, activation='linear', kernel_initializer=init))\n",
    "    model.compile(loss=tf.keras.losses.Huber(), optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_qs(model, state, step):\n",
    "    return model.predict(state.reshape([1, state.shape[0]]))[0]\n",
    "\n",
    "\n",
    "def train(env, replay_memory, model, target_model, done):\n",
    "    learning_rate = 0.7 # Learning rate\n",
    "    discount_factor = 0.618\n",
    "\n",
    "    MIN_REPLAY_SIZE = 1000\n",
    "    if len(replay_memory) < MIN_REPLAY_SIZE:\n",
    "        return\n",
    "\n",
    "    batch_size = 64 * 2\n",
    "    error_flag = True\n",
    "    counter = 1\n",
    "    while error_flag:\n",
    "        try:\n",
    "            mini_batch = random.sample(replay_memory, batch_size)\n",
    "            current_states = np.array([transition[0] for transition in mini_batch])\n",
    "            error_flag = False\n",
    "        except:\n",
    "            print(f\"Failure occured for {counter}\")\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "    current_qs_list = model.predict(current_states)\n",
    "    new_current_states = np.array([transition[3] for transition in mini_batch])\n",
    "    future_qs_list = target_model.predict(new_current_states)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for index, (observation, action, reward, new_observation, done) in enumerate(mini_batch):\n",
    "        if not done:\n",
    "            max_future_q = reward + discount_factor * np.max(future_qs_list[index])\n",
    "        else:\n",
    "            max_future_q = reward\n",
    "\n",
    "        current_qs = current_qs_list[index]\n",
    "        current_qs[action] = (1 - learning_rate) * current_qs[action] + learning_rate * max_future_q\n",
    "\n",
    "        X.append(observation)\n",
    "        Y.append(current_qs)\n",
    "    model.fit(np.array(X), np.array(Y), batch_size=batch_size, verbose=0, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running episode 0\n",
      "Currently running episode 1\n",
      "Currently running episode 2\n",
      "Currently running episode 3\n",
      "Currently running episode 4\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1 # Epsilon-greedy algorithm in initialized at 1 meaning every step is random at the start\n",
    "max_epsilon = 1 # You can't explore more than 100% of the time\n",
    "min_epsilon = 0.01 # At a minimum, we'll always explore 1% of the time\n",
    "decay = 0.01\n",
    "\n",
    "# 1. Initialize the Target and Main models\n",
    "# Main Model (updated every 4 steps)\n",
    "model = agent([len(env.observation_space)], len(env.action_space))\n",
    "# Target Model (updated every 100 steps)\n",
    "target_model = agent([len(env.observation_space)], len(env.action_space))\n",
    "target_model.set_weights(model.get_weights())\n",
    "\n",
    "replay_memory = deque(maxlen=50_000)\n",
    "\n",
    "target_update_counter = 0\n",
    "\n",
    "# X = states, y = actions\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "steps_to_update_target_model = 0\n",
    "\n",
    "for episode in range(train_episodes):\n",
    "    print(f\"Currently running episode {episode}\")\n",
    "    steps = 0\n",
    "    total_training_rewards = 0\n",
    "    observation = env.reset()\n",
    "    steps = 0\n",
    "    while steps < 10:\n",
    "        steps += 1\n",
    "        steps_to_update_target_model += 1\n",
    "        random_number = np.random.rand()\n",
    "        # 2. Explore using the Epsilon Greedy Exploration Strategy\n",
    "        if random_number <= epsilon:\n",
    "            # Explore\n",
    "            action = random.choice(env.action_space)\n",
    "        else:\n",
    "            # Exploit best known action\n",
    "            # model dims are (batch, env.observation_space.n)\n",
    "            encoded = observation\n",
    "            # encoded_reshaped = encoded.reshape([1, encoded.shape[0]])\n",
    "            predicted = model.predict(encoded).flatten()\n",
    "            action = np.argmax(predicted)\n",
    "        new_observation, reward, done, info = env.step(action)\n",
    "        replay_memory.append([observation, action, reward, new_observation, done])\n",
    "\n",
    "        # 3. Update the Main Network using the Bellman Equation\n",
    "        if steps_to_update_target_model % 4 == 0 or done:\n",
    "            mini_batch = train(env, replay_memory, model, target_model, done)\n",
    "\n",
    "        observation = new_observation\n",
    "        total_training_rewards += reward\n",
    "\n",
    "        if done:\n",
    "            print('Total training rewards: {} after n steps = {} with final reward = {}'.format(total_training_rewards, episode, reward))\n",
    "            total_training_rewards += 1\n",
    "\n",
    "            if steps_to_update_target_model >= 100:\n",
    "                print('Copying main network weights to the target network weights')\n",
    "                target_model.set_weights(model.get_weights())\n",
    "                steps_to_update_target_model = 0\n",
    "            break\n",
    "\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon) * np.exp(-decay * episode)\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x12ccd4370>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
